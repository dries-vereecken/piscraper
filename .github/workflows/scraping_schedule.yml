name: Scheduled Scraping

on:
  schedule:
    # Run at 4:00, 10:00, and 16:00 UTC every day (6:00, 12:00, 18:00 CET)
    - cron: '0 4 * * *'
    - cron: '0 10 * * *'
    - cron: '0 16 * * *'
  # Allow manual triggering
  workflow_dispatch:

# Removed permissions since we no longer commit to git

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    # Add environment variables
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
    
    steps:
    - uses: actions/checkout@v3
      with:
        path: "Schedule scraper"
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Setup Chrome
      run: |
        wget -q https://dl.google.com/linux/chrome/deb/pool/main/g/google-chrome-stable/google-chrome-stable_136.0.7103.92-1_amd64.deb
        sudo dpkg -i google-chrome-stable_136.0.7103.92-1_amd64.deb
        google-chrome --version
    
    - name: Setup ChromeDriver
      run: |
        # Get Chrome version
        CHROME_VERSION=$(google-chrome --version | awk '{print $3}' | cut -d'.' -f1)
        echo "Chrome version: $CHROME_VERSION"
        
        # Download and install ChromeDriver
        wget -q "https://storage.googleapis.com/chrome-for-testing-public/136.0.7103.92/linux64/chromedriver-linux64.zip"
        unzip -q chromedriver-linux64.zip
        sudo mv chromedriver-linux64/chromedriver /usr/local/bin/
        sudo chmod +x /usr/local/bin/chromedriver
        
        # Verify installation
        echo "ChromeDriver version:"
        chromedriver --version
        
    - name: Install dependencies
      working-directory: "Schedule scraper"
      run: |
        python -m pip install --upgrade pip
        pip install -e .
        
    - name: Run scrapers and write to database
      working-directory: "Schedule scraper"
      run: |
        echo "üöÄ Starting scraping and database write..."
        
        echo "Running Koepel scraper..."
        python run_scrapers.py koepel || echo "‚ö†Ô∏è Warning: Koepel scraper failed"
        
        echo "Running CoolCharm scraper..."
        python -c "import sys; sys.path.insert(0, 'src'); from scrapers.coolcharm import main; main()" || echo "‚ö†Ô∏è Warning: CoolCharm scraper failed"
        
        echo "Running Rite scraper..."
        python -c "import sys; sys.path.insert(0, 'src'); from scrapers.rite import main; main()" || echo "‚ö†Ô∏è Warning: Rite scraper failed"
        
        echo "Running RowReformer scraper..."
        python -c "import sys; sys.path.insert(0, 'src'); from scrapers.rowreformer import main; main()" || echo "‚ö†Ô∏è Warning: RowReformer scraper failed"
        
        echo "‚úÖ Scraping completed - data written to bronze layer"
        
    - name: Run silver layer aggregation
      working-directory: "Schedule scraper"
      run: |
        echo "üîÑ Running bronze ‚Üí silver aggregation..."
        python -c "import sys; sys.path.insert(0, 'src'); from silver_layer.aggregator import main; main()" || echo "‚ö†Ô∏è Warning: Silver aggregation failed"
        echo "‚úÖ Silver layer aggregation completed" 
